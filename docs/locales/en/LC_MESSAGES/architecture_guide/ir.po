# SOME DESCRIPTIVE TITLE.
# Copyright (C) nndeploy
# This file is distributed under the same license as the nndeploy package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: nndeploy\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-05-10 17:38+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: en <LL@li.org>\n"
"Language: en\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"Generated-By: Babel 2.17.0\n"

#: ../../architecture_guide/ir.md:2 cd3f6676260a42dba40efa9f11b9005a
msgid ""
"我们现在切到 IDE 来讲解IR 部分的代码具体的实现。IR 代码的位置在根目录下的 framework 目录。我们先点开 include "
"目录，看一下头文件，找到 ir 目录下的 ir.h，这是我们要讲的一个文件，还有 op_param.h 是另外一个文件，对应的源文件在 source "
"目录。"
msgstr ""
"We are now switching to the IDE to explain the specific implementation of "
"the IR part of the code. The location of the IR code is under the framework "
"directory in the root directory. We first open the include directory to look"
" at the header files, find ir.h under the ir directory, which is one of the "
"files we are going to discuss, and op_param.h is another file, with the "
"corresponding source files located in the source directory."

#: ../../architecture_guide/ir.md:4 67f7527b898648548f4e74738e605c98
msgid ""
"首先看一下 "
"ir.h，针对IR这个模块，先讲成员变量，然后再讲成员函数，因为成员函数是辅助成员变量做事情的，把成员变量讲清楚了，那对应的函数其实你也大概能知道它到底怎么回事。"
msgstr ""
"First, let's look at ir.h. For the IR module, we will first discuss the "
"member variables, and then the member functions, because member functions "
"assist the member variables in performing tasks. Once the member variables "
"are clearly explained, you can roughly understand what the corresponding "
"functions are about."

#: ../../architecture_guide/ir.md:6 59ae3d3e42b04226b08e520e5faa4566
msgid "我们整个 NNDeploy 的 IR 是很大程度借鉴了 ONNX。"
msgstr "The IR of our entire NNDeploy largely draws on ONNX."

#: ../../architecture_guide/ir.md:8 909701539d424ef085f6f50887c22a60
msgid "我们首先看最顶层的数据结构ModelDesc，我们先看一下 ModelDesc 的成员变量，"
msgstr ""
"First, we look at the top-level data structure ModelDesc. Let's first "
"examine the member variables of ModelDesc."

#: ../../architecture_guide/ir.md:11 5382c650659e4061bb6265cd7067d512
msgid ""
"首先这个模型需要名称，所以我们有一个 string name。 模型会有很多元数据，比如说它的生产者是谁？它在什么训练框架训出来的，所以我们有一个 "
"unordered_map 来存放一些 metadata。"
msgstr ""
"First, the model needs a name, so we have a string name. The model will have"
" a lot of metadata, such as who produced it? On what training framework was "
"it trained? So we have an unordered_map to store some metadata."

#: ../../architecture_guide/ir.md:14 96bd1b27e6da4a8dad817cbf2c6bd9e3
msgid ""
"整个模型会有输入，他可能是多个输入，所以这里是vector的形式，这个输入是一种特殊的结构，我们把他设计为了ValueDesc，等下我们会跳到 "
"ValueDesc 去看一下它具体会有哪些信息。然后模型会有输出，它跟输入是同样的数据结构。"
msgstr ""
"The entire model will have inputs, possibly multiple inputs, so here it's in"
" the form of a vector. This input is a special structure, which we've "
"designed as ValueDesc. Later, we will jump to ValueDesc to see what specific"
" information it contains. Then the model will have outputs, which are the "
"same data structure as the inputs."

#: ../../architecture_guide/ir.md:16 48257f94be67479696713ca9299d56c7
msgid "模型是由一系列算子构成的，这一列算子由 vector 来存储。描述算子的具体信息由 OpDesc 决定。"
msgstr ""
"The model is composed of a series of operators, and this series of operators"
" is stored by a vector. The specific information describing the operators is"
" determined by OpDesc."

#: ../../architecture_guide/ir.md:18 8da4e23e359e4d939756afe0a3da5d6d
msgid ""
"然后是描述模型的权重，模型的单个权重用 tensor 表示，权重需要与算子关联，我们把权重设为一个 map 的形式，string 和 tensor 的 "
"map 形式。这样 tensor 与算子关联就会更加直接，因为 OpDesc 只要存放这个权重的名字即可，算子和权重就关联起来了。"
msgstr ""
"Then there's the description of the model's weights. A single weight of the "
"model is represented by a tensor. Weights need to be associated with "
"operators, so we set the weights in the form of a map, a map of string and "
"tensor. This makes the association between tensors and operators more "
"direct, because OpDesc only needs to store the name of the weight, and the "
"operator and weight are then associated."

#: ../../architecture_guide/ir.md:20 c2db7a9aee804c87b9de061b3678bff4
msgid "好了，我们对最顶层的数据结构有了基本的认识，现在来看一下 ValueDesc。主要是服务模型的输入输出，"
msgstr ""
"Alright, we have a basic understanding of the top-level data structure. Now "
"let's look at ValueDesc. It mainly serves the model's inputs and outputs."

#: ../../architecture_guide/ir.md:22 76b8b16b22504b829c6ab74954b8d5a9
msgid ""
"以模型的输入为例，它必须有一个名称，就像我们使用 netron "
"打开模型时看到的那样，输入都有名称。模型的输入还会有那些信息呢，例如输入的数据类型（fp32呢，还是fp16呢）、输入的形状多大呢，以 YOLOv11s"
" 为例，其默认输入类型是fp32，输入形状是 1 × 3 × 600 × 600。输出跟输入的要求一致。"
msgstr ""
"Taking the model's input as an example, it must have a name, just like when "
"we open the model with netron, the inputs have names. The model's inputs "
"will also have other information, such as the input data type (fp32 or "
"fp16), the shape of the input. Taking YOLOv11s as an example, its default "
"input type is fp32, and the input shape is 1 × 3 × 600 × 600. The "
"requirements for outputs are consistent with those for inputs."

#: ../../architecture_guide/ir.md:24 800db14621ba43dfae8b9778847a6005
msgid ""
"现在又很多动态shape的模型，你可以在后续在线推理时确定其形状，因此 shape 是可选的。可以做形状推理，也可以做类型推理，所以其类型也是可选的。"
msgstr ""
"Now there are many models with dynamic shapes. You can determine their shape"
" during online inference later, so the shape is optional. Shape inference "
"can be performed, and type inference can also be performed, so its type is "
"also optional."

#: ../../architecture_guide/ir.md:26 a39ffd9eca264849880d0c3569fd64b3
msgid ""
"讲完了 ValueDesc，我们再跳回 ModelDesc 这个最顶层数据结构。我们再开始讲 "
"OpDesc。我们同样跳进去看一下。首先还是先讲成员变量。算子会有名称，算子会有类型，是卷积类型还是 ReLU 类型？"
msgstr ""
"After discussing ValueDesc, we jump back to the top-level data structure "
"ModelDesc. We then start discussing OpDesc. Similarly, we jump in to take a "
"look. First, we'll talk about the member variables. The operator will have a"
" name, and the operator will have a type, such as whether it's a convolution"
" type or a ReLU type?"

#: ../../architecture_guide/ir.md:28 146d3708775146089cefc1b464f08458
msgid ""
"有了名字和 op_type，算子会有输入和输出。对于某些算子而言，它可以有多个输入，对于某些算子而言，它可以有多个输出，所以输入输出是 vector 的"
" string 形式。"
msgstr ""
"With a name and op_type, the operator will have inputs and outputs. For some"
" operators, they can have multiple inputs, and for some operators, they can "
"have multiple outputs, so the inputs and outputs are in the form of a vector"
" of strings."

#: ../../architecture_guide/ir.md:30 22968eab07a7459aa7c54dc75cdfbeca
msgid ""
"这里会有一个问题，为什么算子的输入是用 string 来表示？有了名字和 "
"op_type，那算子会有输入算子会有输出。对于某些算子而言，它可以有多个输入，对于某些算子而言，它可以有多个输出，所以输入输出是 vector 的 "
"string 形式。那这里会有一个问题，为什么算子的输入是用 string 来表示？这里我们详细解释一下具体原因。在 IR "
"阶段，它并不涉及执行，我们并不需要为输入输出分配实际的数据。我们只需要全局有一个唯一的标识符即可。那全局的唯一标识符什么是一种最划算的选择呢？那 "
"string 就是一个最划算的选择，最划算、最易读的选择。所以在 IR 阶段，我们算子的输入输出通过 string 来描述。"
msgstr ""
"Here a question arises, why are the operator's inputs represented by "
"strings? With a name and op_type, the operator will have inputs and outputs."
" For some operators, they can have multiple inputs, and for some operators, "
"they can have multiple outputs, so the inputs and outputs are in the form of"
" a vector of strings. Here a question arises, why are the operator's inputs "
"represented by strings? Here we explain the specific reason in detail. At "
"the IR stage, it does not involve execution, we do not need to allocate "
"actual data for inputs and outputs. We only need a globally unique "
"identifier. What is the most economical choice for a globally unique "
"identifier? A string is the most economical, the most readable choice. "
"Therefore, at the IR stage, the inputs and outputs of our operators are "
"described by strings."

#: ../../architecture_guide/ir.md:32 c6f5a11d4bec4ac3a96c27f3398bd9ad
msgid ""
"那这个算子如何关联我们前面提到的那个权重呢？我们以卷积为例，卷积它有 weight，我们是把卷积的权重当成这个算子的输入来看待。那它的某个 input "
"就是那个权重的名字。这个权重的名字又关联到了 ModelDesc的成员变量weights中，然后这样就绑定了算子和权重。"
msgstr ""
"How does this operator associate with the weights we mentioned earlier? "
"Let's take convolution as an example. Convolution has weights, we treat the "
"convolution's weights as an input to the operator. Then one of its inputs is"
" the name of the weight. The name of the weight is associated with the "
"member variable weights in ModelDesc, thus binding the operator and the "
"weight."

#: ../../architecture_guide/ir.md:34 799c70b52f58421a9a84030222f16a33
msgid ""
"通过这个 input output 如何表达计算图呢？这里举个例子，我们可以看到对于卷积而言，它的输入是 input 和 weight，它的输出是 "
"output，那对于下一个算子 ReLU 而言，它的输入 inputs 是这个卷积的 output，那这样子卷积和 ReLU 就关联起来了。"
msgstr ""
"How to express the computation graph through these inputs and outputs? "
"Here's an example, we can see that for convolution, its inputs are input and"
" weight, its output is output, then for the next operator ReLU, its input is"
" the output of this convolution, thus associating convolution and ReLU."

#: ../../architecture_guide/ir.md:36 f1b368c86ae24c9cadff7d8db4ebcadc
msgid ""
"有时候我们需要在ir阶段调试算子的输入输出的类型以及形状，在 IR 阶段就可以有 data type "
"的信息，就数据类型的信息，还可以有形状的信息，我们可以让这个 输入输出 和 "
"ModelDesc的成员变量value关联祁连。这样算子会具有更丰富的信息，更有利于去调试你的 IR。"
msgstr ""
"Sometimes we need to debug the input and output types and shapes of "
"operators at the IR stage. At the IR stage, we can have data type "
"information, that is, the information of the data type, and also the "
"information of the shape. We can associate this input output with the member"
" variable value of ModelDesc. This way, the operator will have richer "
"information, more conducive to debugging your IR."

#: ../../architecture_guide/ir.md:38 0939f8055daf4da1ae4d016fed2d6a4c
msgid ""
"算子的描述还需要描述参数，这里用op_param的智能来表示。OpDesc一旦构建起来，就会根据op_type来创建一个特定的算子参数。有些没有参数的算子，例如卷积，这个指针就为空。具体算子参数的实现在op_param中，我们快速过一篇卷积的参数，例如这里的滑窗窗口的大小，padding的大小，这里有一个值得注意的点是，卷积其实可以很多激活函数融合，nndeploy再ir层面提供了融合的可能，我们这里又融合进来的算子类型，融合的算子的参数。"
msgstr ""
"The description of the operator also needs to describe parameters, here "
"using op_param's intelligence to represent. Once OpDesc is constructed, it "
"will create a specific operator parameter based on op_type. Some operators "
"do not have parameters, such as convolution, where this pointer is null. The"
" implementation of specific operator parameters is in op_param, we quickly "
"go through a convolution parameter, such as the size of the sliding window "
"here, the size of padding, there is a noteworthy point here, convolution can"
" actually fuse many activation functions, nndeploy provides the possibility "
"of fusion at the ir layer level, here we also fuse the incoming operator "
"types, the parameters of the fused operators."

#: ../../architecture_guide/ir.md:40 2cd4d80e6281445089df92bbd5210296
msgid ""
"我们讲完了整个 ModelDesc相关的的成员变量。我们再来看一些成员函数。对于 IR 而言，它需要序列化为权重文件，权重文件需要被反序列化为 IR，"
msgstr ""
"We have covered all the member variables related to ModelDesc. Let's look at"
" some member functions next. For IR, it needs to be serialized into a weight"
" file, the weight file needs to be deserialized into IR,"

#: ../../architecture_guide/ir.md:42 ef85f8c539f24221b7e35547eb524c1f
msgid ""
"所以 IR "
"需要支持的函数是序列化和反序列化。ModelDesc提供嘞序列化以及反序列化成员函数，其中模型结构序列化为json文件，模型权重序列化为safetensors文件，后续我们在模型解释章节会详细讲我们为什么选择"
" JSON 和 safetensors 的格式。"
msgstr ""
"So the functions IR needs to support are serialization and deserialization. "
"ModelDesc provides serialization and deserialization member functions, where"
" the model structure is serialized into a json file, the model weights are "
"serialized into safetensors files, later in the model interpretation chapter"
" we will detail why we chose JSON and safetensors formats."

#: ../../architecture_guide/ir.md:44 1d087a5e58b14411b83ecf8f000af47d
msgid "在跳到ValueDesc去看下他相关的接口，同样也是序列化和反序列的成员函数"
msgstr ""
"Jumping to ValueDesc to look at its related interfaces, also serialization "
"and deserialization member functions"

#: ../../architecture_guide/ir.md:46 7fbabbb5b01446edb4124b461dfdefec
msgid "再跳到OpDesc看下相关接口，还是序列化和反序列的成员函数"
msgstr ""
"Jumping to OpDesc to look at related interfaces, still serialization and "
"deserialization member functions"

#: ../../architecture_guide/ir.md:48 77c4b91a981a4d508f3844e5186c38ac
msgid ""
"整个的 ir "
"已经能够表达模型结构和模型权重。ModelDesc的核心数据以标准库为主，尽可能少的三方依赖数据，然后是尽可能地紧凑，比如说我们算子的输入输出是 "
"string，通过分层的结构设计，序列化与反序列也较为便捷。"
msgstr ""
"The entire ir is already capable of expressing the model structure and model"
" weights. The core data of ModelDesc is mainly based on standard libraries, "
"with as few third-party dependencies as possible, and then as compact as "
"possible, for example, our operator's input and output are strings, through "
"layered structure design, serialization and deserialization are also more "
"convenient."

#: ../../architecture_guide/ir.md:50 6e16c7b980084e30a9bb4f6866402169
msgid "好了，我们对 IR 代码实现的部分的介绍，到这里就结束了。"
msgstr ""
"Alright, our introduction to the IR code implementation part ends here."
